## 海量数据处理

海量数据处理，网上已经有很多总结，方法大多类似，与其说套路，其实最终回归对基本算法的灵活应用。

对于海量数据，数据量非常大，并且要考虑到内存空间有限。

方法：

> **1. 分冶**

适用场景：数据量大无法加载到内存。

> **2. 哈希(Hash)**

缺点：耗内存，需要将数据全部装入内存。

适用场景：快速查找，需要总数量可以放入内存。

> **3. 位集(BitMap)**

适用场景：解决海量数据寻找重复、判断个别元素是否在海量数据当中。

> **4. 堆(Heap)**

适用场景：处理海量处理中 Top N 的问题(最大或最小)，要求 N 不大，使得堆可以放入内存。

**好好研读参考相关文章，自己去思考和分析。**

## 参考

* [七月July 海量数据处理](http://blog.csdn.net/v_july_v/article/details/7382693)
* [海量数据解决思路之Hash算法](http://c.colabug.com/thread-1148595-1-1.html)
